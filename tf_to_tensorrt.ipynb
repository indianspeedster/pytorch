{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNGtdMSWQC2nyYq8WcZm7V7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/indianspeedster/pytorch/blob/master/tf_to_tensorrt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m pip install --upgrade tensorrt\n",
        "!python3 -m pip install --upgrade tensorrt_lean\n",
        "!python3 -m pip install --upgrade tensorrt_dispatch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpBxi1MaL3Wd",
        "outputId": "ed198eee-8678-450a-a045-cc4381713e93"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorrt\n",
            "  Downloading tensorrt-8.6.1.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: tensorrt\n",
            "  Building wheel for tensorrt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt: filename=tensorrt-8.6.1-py2.py3-none-any.whl size=16972 sha256=0d060d72d4a66b1686e5e5ec16c21f7caca2b92a55eef451edc46d1f8674c84f\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/29/56/abdffd4c604f255b5254bef3f1c598ab7811ea020540599438\n",
            "Successfully built tensorrt\n",
            "Installing collected packages: tensorrt\n",
            "Successfully installed tensorrt-8.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorrt\n",
        "assert tensorrt.Builder(tensorrt.Logger())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgUV_iZAXeN8",
        "outputId": "ca614bd2-cc3b-426f-8347-6118c44d312a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Without tensor Rt implementation"
      ],
      "metadata": {
        "id": "KjEgO0q1ppDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "# Navigate to correct position in filesystem\n",
        "#script_directory = os.path.dirname(os.path.abspath(sys.argv[0]))\n",
        "#os.chdir(script_directory)\n",
        "\n",
        "# Set up the model\n",
        "INPUT_IMG_SIZE = 224\n",
        "INPUT_IMG_SHAPE = (224, 224, 3)\n",
        "model = tf.keras.applications.MobileNetV2(\n",
        "  input_shape=INPUT_IMG_SHAPE\n",
        ")\n",
        "@tf.function\n",
        "def serve(x):\n",
        "  return model(x, training=False)\n",
        "\n",
        "\n",
        "# Prepare and pass the input image\n",
        "image_path = 'parrot.jpg'\n",
        "img = Image.open(image_path).convert('RGB')\n",
        "img = img.resize((INPUT_IMG_SIZE, INPUT_IMG_SIZE), Image.BICUBIC)\n",
        "input_data = np.array(img)/255.0\n",
        "input_data = input_data.reshape(1, INPUT_IMG_SIZE, INPUT_IMG_SIZE, 3)\n",
        "\n",
        "# First prediction is slow, we won't count it\n",
        "output = serve(input_data)\n",
        "\n",
        "# Now, start counting!\n",
        "start_time = time.time()\n",
        "\n",
        "# Make a prediction!\n",
        "output = serve(input_data)\n",
        "\n",
        "# Get and print the result\n",
        "inf_time =  time.time() - start_time\n",
        "print(f\"time: {inf_time}s\" )\n",
        "\n",
        "top_3 = np.argsort(output.numpy().squeeze())[-3:][::-1]\n",
        "url = tf.keras.utils.get_file(\n",
        "    'ImageNetLabels.txt',\n",
        "    'https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')\n",
        "imagenet_labels = np.array(open(url).read().splitlines())[1:]\n",
        "\n",
        "for i in top_3:\n",
        "    print('{:.6f}'.format(output.numpy()[0, i]), ':',  imagenet_labels[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eyTR8czVtVz",
        "outputId": "4bceea8a-c7f1-4f1a-8496-79255d3b69c8"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 0.007984638214111328s\n",
            "0.875274 : macaw\n",
            "0.005244 : bee eater\n",
            "0.004900 : flamingo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Save the above model"
      ],
      "metadata": {
        "id": "9qZSJfTIpz2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SAVED_MODEL_DIR=\"./models/native_saved_model\"\n",
        "model.save(SAVED_MODEL_DIR)"
      ],
      "metadata": {
        "id": "e2es6zxXV6gj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Import and build tensorrt"
      ],
      "metadata": {
        "id": "_JtE6Wfer1Eu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorrt\n",
        "assert tensorrt.Builder(tensorrt.Logger())"
      ],
      "metadata": {
        "id": "y6q6jymdr0bK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### convert the model for tensorrt inference"
      ],
      "metadata": {
        "id": "7rUO0G4Fp4xn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
        "\n",
        "converter = trt.TrtGraphConverterV2(\n",
        "   input_saved_model_dir=SAVED_MODEL_DIR,\n",
        "   precision_mode=trt.TrtPrecisionMode.FP16\n",
        ")\n",
        "\n",
        "trt_func = converter.convert()\n",
        "converter.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "934S5rbSWA0W",
        "outputId": "c6431fa1-90b4-4b42-c814-416cadac0a95"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRTEngineOP Name                 Device        # Nodes # Inputs      # Outputs     Input DTypes       Output Dtypes      Input Shapes       Output Shapes     \n",
            "================================================================================================================================================================\n",
            "TRTEngineOp_000_000              device:GPU:0  421     1             1             ['float32']        ['float32']        [[-1, 224, 224 ... [[-1, 1000]]      \n",
            "\n",
            "\t- AddV2: 10x\n",
            "\t- BiasAdd: 1x\n",
            "\t- Const: 264x\n",
            "\t- Conv2D: 35x\n",
            "\t- DepthwiseConv2dNative: 17x\n",
            "\t- FusedBatchNormV3: 52x\n",
            "\t- MatMul: 1x\n",
            "\t- Mean: 1x\n",
            "\t- Pad: 4x\n",
            "\t- Relu6: 35x\n",
            "\t- Softmax: 1x\n",
            "\n",
            "================================================================================================================================================================\n",
            "[*] Total number of TensorRT engines: 1\n",
            "[*] % of OPs Converted: 99.53% [421/423]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### build the model to specify the input shape"
      ],
      "metadata": {
        "id": "4tkIjTU2p-VR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "data_float32 = np.array(input_data, dtype=np.float32)\n",
        "\n",
        "def input_fn():\n",
        "    yield [data_float32]\n",
        "\n",
        "converter.build(input_fn=input_fn)"
      ],
      "metadata": {
        "id": "FFLYmuxgYURK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Save the tftrt model"
      ],
      "metadata": {
        "id": "vqgKZ8VrqIjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_SAVED_MODEL_DIR=\"./models/tftrt_saved_model\"\n",
        "converter.save(output_saved_model_dir=OUTPUT_SAVED_MODEL_DIR)"
      ],
      "metadata": {
        "id": "FHzgaJXbrgOm"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Make inference"
      ],
      "metadata": {
        "id": "E5BrwpBwrku3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
        "\n",
        "# Navigate to correct position in filesystem\n",
        "#script_directory = os.path.dirname(os.path.abspath(sys.argv[0]))\n",
        "#os.chdir(script_directory)\n",
        "\n",
        "# Set up the model\n",
        "INPUT_IMG_SIZE = 224\n",
        "INPUT_IMG_SHAPE = (224, 224, 3)\n",
        "loaded_model = tf.saved_model.load(OUTPUT_SAVED_MODEL_DIR)\n",
        "infer = loaded_model.signatures['serving_default']\n",
        "\n",
        "\n",
        "# Prepare and pass the input image\n",
        "image_path = 'parrot.jpg'\n",
        "img = Image.open(image_path).convert('RGB')\n",
        "img = img.resize((INPUT_IMG_SIZE, INPUT_IMG_SIZE), Image.BICUBIC)\n",
        "input_data = np.array(img)/255.0\n",
        "input_data = input_data.reshape(1, INPUT_IMG_SIZE, INPUT_IMG_SIZE, 3)\n",
        "data_float32 = np.array(input_data, dtype=np.float32)\n",
        "image_tensor = tf.convert_to_tensor(data_float32)\n",
        "# First prediction is slow, we won't count it\n",
        "output = infer(image_tensor)\n",
        "\n",
        "# Now, start counting!\n",
        "start_time = time.time()\n",
        "\n",
        "# Make a prediction!\n",
        "output = infer(image_tensor)\n",
        "\n",
        "# Get and print the result\n",
        "inf_time =  time.time() - start_time\n",
        "print(f\"time: {inf_time}s\" )\n",
        "\n",
        "top_3 = np.argsort(output[\"predictions\"].numpy().squeeze())[-3:][::-1]\n",
        "url = tf.keras.utils.get_file(\n",
        "    'ImageNetLabels.txt',\n",
        "    'https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')\n",
        "imagenet_labels = np.array(open(url).read().splitlines())[1:]\n",
        "\n",
        "for i in top_3:\n",
        "    print('{:.6f}'.format(output[\"predictions\"].numpy()[0, i]), ':',  imagenet_labels[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zzHS_wpnyvY",
        "outputId": "9442ef24-097f-4eda-edce-2807987ccb95"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 0.003282785415649414s\n",
            "0.877158 : macaw\n",
            "0.005335 : bee eater\n",
            "0.004814 : flamingo\n"
          ]
        }
      ]
    }
  ]
}